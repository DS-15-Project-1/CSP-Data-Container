{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58 entries, 0 to 57\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Unnamed: 0     58 non-null     int64  \n",
      " 1   network        58 non-null     object \n",
      " 2   station        58 non-null     object \n",
      " 3   location       58 non-null     int64  \n",
      " 4   channel        58 non-null     object \n",
      " 5   starttime      58 non-null     object \n",
      " 6   endtime        58 non-null     object \n",
      " 7   sampling_rate  58 non-null     float64\n",
      " 8   data           58 non-null     object \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 4.2+ KB\n",
      "None\n",
      "   Unnamed: 0 network station  location channel            starttime  \\\n",
      "0           0      ZZ    FWU3        10     HHE  2019-12-26T00:00:00   \n",
      "1           1      ZZ    FWU3        10     HHE  2019-11-02T00:00:00   \n",
      "2           2      ZZ    FWU3        10     HHE  2019-12-22T00:00:00   \n",
      "3           3      ZZ    FWU3        10     HHE  2019-12-15T00:00:00   \n",
      "4           4      ZZ    FWU3        10     HHE  2019-11-28T00:00:00   \n",
      "\n",
      "                      endtime  sampling_rate  \\\n",
      "0  2019-12-26T23:59:59.996000          250.0   \n",
      "1  2019-11-02T23:59:59.996000          250.0   \n",
      "2  2019-12-22T23:59:59.996000          250.0   \n",
      "3  2019-12-15T23:59:59.996000          250.0   \n",
      "4  2019-11-28T23:59:59.996000          250.0   \n",
      "\n",
      "                                              data  \n",
      "0  [ -2718   -384  -1595 ...  11287 -15821  -3071]  \n",
      "1        [ 1313  1352  1389 ... -1601   130  1031]  \n",
      "2        [-7410 -5221  3344 ... -3956  4921 11622]  \n",
      "3  [-11938  -1006  11098 ...   -350   -485   -682]  \n",
      "4        [-6507 -5165 -3379 ...  -315    59  -251]  \n",
      "    Unnamed: 0 network station  location channel            starttime  \\\n",
      "53          20      ZZ    FWU3        10     HHE  2019-12-20T00:00:00   \n",
      "54          21      ZZ    FWU3        10     HHE  2019-12-03T00:00:00   \n",
      "55          22      ZZ    FWU3        10     HHE  2019-10-31T00:00:00   \n",
      "56          23      ZZ    FWU3        10     HHE  2019-11-17T00:00:00   \n",
      "57          24      ZZ    FWU3        10     HHE  2019-11-16T00:00:00   \n",
      "\n",
      "                       endtime  sampling_rate  \\\n",
      "53  2019-12-20T23:59:59.996000          250.0   \n",
      "54  2019-12-03T23:59:59.996000          250.0   \n",
      "55  2019-10-31T23:59:59.996000          250.0   \n",
      "56  2019-11-17T23:59:59.996000          250.0   \n",
      "57  2019-11-16T23:59:59.996000          250.0   \n",
      "\n",
      "                                               data  \n",
      "53  [  1250   1737   2299 ...  -1258 -12200  -7834]  \n",
      "54        [-1099 -1461 -1416 ...  3259 -3334 -7933]  \n",
      "55        [-1258 -1252 -1932 ... -2143 -2147 -2185]  \n",
      "56        [ -283  -240   -45 ... -3532 -9727 -8701]  \n",
      "57              [-114 1935 2881 ... -325 -407   11]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_and_save_csv_files(file1, file2, output_path):\n",
    "    \"\"\"\n",
    "    Merges two CSV files into one and saves the merged data as a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    file1 (str): Path to the first CSV file.\n",
    "    file2 (str): Path to the second CSV file.\n",
    "    output_path (str): Path to save the merged CSV file.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The merged DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the two CSV files into DataFrames\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    # Merge the DataFrames (concatenate them along the rows)\n",
    "    merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # Save the merged DataFrame to a new CSV file\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "    # Return the merged DataFrame\n",
    "    return merged_df\n",
    "\n",
    "# Example usage\n",
    "file1 = '/notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data1.csv'\n",
    "file2 = '/notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data2.csv'\n",
    "output_path = '/notebooks/Mine-folder/output/FWU3/currentCSVs/HHEDcsv.csv'\n",
    "\n",
    "# Merge the CSV files and save the result\n",
    "merged_dataframe = merge_and_save_csv_files(file1, file2, output_path)\n",
    "\n",
    "# Print some information about the merged DataFrame\n",
    "print(merged_dataframe.info())\n",
    "print(merged_dataframe.head())\n",
    "print(merged_dataframe.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file: /notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data1.csv\n",
      "\n",
      "Checking file: /notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data2.csv\n",
      "\n",
      "File '/notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data1.csv' does not contain the Unnamed column.\n",
      "\n",
      "File '/notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data2.csv' does not contain the Unnamed column.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def findUnnamedColumn(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return 'Unnamed' in df.columns.tolist()\n",
    "\n",
    "def main():\n",
    "    file1 = '/notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data1.csv'\n",
    "    file2 = '/notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data2.csv'\n",
    "\n",
    "    print(f\"Checking file: {file1}\")\n",
    "    hasUnnamed1 = findUnnamedColumn(file1)\n",
    "    \n",
    "    print(f\"\\nChecking file: {file2}\")\n",
    "    hasUnnamed2 = findUnnamedColumn(file2)\n",
    "\n",
    "    if hasUnnamed1:\n",
    "        print(f\"\\nFile '{file1}' contains the Unnamed column.\")\n",
    "    else:\n",
    "        print(f\"\\nFile '{file1}' does not contain the Unnamed column.\")\n",
    "\n",
    "    if hasUnnamed2:\n",
    "        print(f\"\\nFile '{file2}' contains the Unnamed column.\")\n",
    "    else:\n",
    "        print(f\"\\nFile '{file2}' does not contain the Unnamed column.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df1: (33, 9)\n",
      "Columns in df1: ['Unnamed: 0', 'network', 'station', 'location', 'channel', 'starttime', 'endtime', 'sampling_rate', 'data']\n",
      "\n",
      "Shape of df2: (25, 9)\n",
      "Columns in df2: ['Unnamed: 0', 'network', 'station', 'location', 'channel', 'starttime', 'endtime', 'sampling_rate', 'data']\n",
      "\n",
      "Common columns: {'network', 'channel', 'station', 'data', 'endtime', 'starttime', 'Unnamed: 0', 'sampling_rate', 'location'}\n",
      "\n",
      "Shape of merged_df: (58, 9)\n",
      "Columns in merged_df: ['Unnamed: 0', 'network', 'station', 'location', 'channel', 'starttime', 'endtime', 'sampling_rate', 'data']\n",
      "\n",
      "Merged DataFrame information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58 entries, 0 to 57\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Unnamed: 0     58 non-null     int64  \n",
      " 1   network        58 non-null     object \n",
      " 2   station        58 non-null     object \n",
      " 3   location       58 non-null     int64  \n",
      " 4   channel        58 non-null     object \n",
      " 5   starttime      58 non-null     object \n",
      " 6   endtime        58 non-null     object \n",
      " 7   sampling_rate  58 non-null     float64\n",
      " 8   data           58 non-null     object \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 4.2+ KB\n",
      "None\n",
      "   Unnamed: 0 network station  location channel            starttime  \\\n",
      "0           0      ZZ    FWU3        10     HHE  2019-12-26T00:00:00   \n",
      "1           1      ZZ    FWU3        10     HHE  2019-11-02T00:00:00   \n",
      "2           2      ZZ    FWU3        10     HHE  2019-12-22T00:00:00   \n",
      "3           3      ZZ    FWU3        10     HHE  2019-12-15T00:00:00   \n",
      "4           4      ZZ    FWU3        10     HHE  2019-11-28T00:00:00   \n",
      "\n",
      "                      endtime  sampling_rate  \\\n",
      "0  2019-12-26T23:59:59.996000          250.0   \n",
      "1  2019-11-02T23:59:59.996000          250.0   \n",
      "2  2019-12-22T23:59:59.996000          250.0   \n",
      "3  2019-12-15T23:59:59.996000          250.0   \n",
      "4  2019-11-28T23:59:59.996000          250.0   \n",
      "\n",
      "                                              data  \n",
      "0  [ -2718   -384  -1595 ...  11287 -15821  -3071]  \n",
      "1        [ 1313  1352  1389 ... -1601   130  1031]  \n",
      "2        [-7410 -5221  3344 ... -3956  4921 11622]  \n",
      "3  [-11938  -1006  11098 ...   -350   -485   -682]  \n",
      "4        [-6507 -5165 -3379 ...  -315    59  -251]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_csv_files(file1, file2, output_path):\n",
    "    # Read both CSV files\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    print(f\"Shape of df1: {df1.shape}\")\n",
    "    print(f\"Columns in df1: {list(df1.columns)}\")\n",
    "    print(f\"\\nShape of df2: {df2.shape}\")\n",
    "    print(f\"Columns in df2: {list(df2.columns)}\")\n",
    "\n",
    "    # Check for common columns\n",
    "    common_columns = set(df1.columns).intersection(set(df2.columns))\n",
    "    print(f\"\\nCommon columns: {common_columns}\")\n",
    "\n",
    "    # Concatenate DataFrames\n",
    "    merged_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "\n",
    "    print(f\"\\nShape of merged_df: {merged_df.shape}\")\n",
    "    print(f\"Columns in merged_df: {list(merged_df.columns)}\")\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# Usage\n",
    "file1 = '/notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data1.csv'\n",
    "file2 = '/notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data2.csv'\n",
    "output_path = '/notebooks/Mine-folder/output/FWU3/currentCSVs/HHEDcsv.csv'\n",
    "\n",
    "# Merge the CSV files\n",
    "merged_dataframe = merge_csv_files(file1, file2, output_path)\n",
    "\n",
    "print(\"\\nMerged DataFrame information:\")\n",
    "print(merged_dataframe.info())\n",
    "print(merged_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inspecting /notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data1.csv:\n",
      "     0        1        2         3        4                    5  \\\n",
      "0  NaN  network  station  location  channel            starttime   \n",
      "1  0.0       ZZ     FWU3        10      HHE  2019-12-26T00:00:00   \n",
      "2  1.0       ZZ     FWU3        10      HHE  2019-11-02T00:00:00   \n",
      "3  2.0       ZZ     FWU3        10      HHE  2019-12-22T00:00:00   \n",
      "4  3.0       ZZ     FWU3        10      HHE  2019-12-15T00:00:00   \n",
      "\n",
      "                            6              7  \\\n",
      "0                     endtime  sampling_rate   \n",
      "1  2019-12-26T23:59:59.996000          250.0   \n",
      "2  2019-11-02T23:59:59.996000          250.0   \n",
      "3  2019-12-22T23:59:59.996000          250.0   \n",
      "4  2019-12-15T23:59:59.996000          250.0   \n",
      "\n",
      "                                                 8  \n",
      "0                                             data  \n",
      "1  [ -2718   -384  -1595 ...  11287 -15821  -3071]  \n",
      "2        [ 1313  1352  1389 ... -1601   130  1031]  \n",
      "3        [-7410 -5221  3344 ... -3956  4921 11622]  \n",
      "4  [-11938  -1006  11098 ...   -350   -485   -682]  \n",
      "\n",
      "Column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "\n",
      "Inspecting /notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data2.csv:\n",
      "     0        1        2         3        4                    5  \\\n",
      "0  NaN  network  station  location  channel            starttime   \n",
      "1  0.0       ZZ     FWU3        10      HHE  2019-12-04T00:00:00   \n",
      "2  1.0       ZZ     FWU3        10      HHE  2019-12-18T00:00:00   \n",
      "3  2.0       ZZ     FWU3        10      HHE  2019-12-07T00:00:00   \n",
      "4  3.0       ZZ     FWU3        10      HHE  2019-11-22T00:00:00   \n",
      "\n",
      "                            6              7  \\\n",
      "0                     endtime  sampling_rate   \n",
      "1  2019-12-04T23:59:59.996000          250.0   \n",
      "2  2019-12-18T23:59:59.996000          250.0   \n",
      "3  2019-12-07T23:59:59.996000          250.0   \n",
      "4  2019-11-22T23:59:59.996000          250.0   \n",
      "\n",
      "                                                 8  \n",
      "0                                             data  \n",
      "1  [ -9043  -8798  -7143 ... -33788 -26054  10376]  \n",
      "2  [ -2976 -11244  15436 ...   2055   1366    865]  \n",
      "3        [-1039 -2527 -3052 ...  1274   529   322]  \n",
      "4        [-2097 -1911 -2522 ... -2123   735   770]  \n",
      "\n",
      "Column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def inspect_csv(file_path):\n",
    "    # Read the CSV file with minimal processing\n",
    "    df = pd.read_csv(file_path, nrows=5, header=None)\n",
    "    \n",
    "    print(f\"\\nInspecting {file_path}:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(df.columns.tolist())\n",
    "\n",
    "def main():\n",
    "    file1 = '/notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data1.csv'\n",
    "    file2 = '/notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data2.csv'\n",
    "\n",
    "    inspect_csv(file1)\n",
    "    inspect_csv(file2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged DataFrame information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57 entries, 0 to 56\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   network        57 non-null     object \n",
      " 1   channel        57 non-null     object \n",
      " 2   station        57 non-null     object \n",
      " 3   data           57 non-null     object \n",
      " 4   endtime        57 non-null     object \n",
      " 5   starttime      57 non-null     object \n",
      " 6   Unnamed: 0     57 non-null     int64  \n",
      " 7   sampling_rate  57 non-null     float64\n",
      " 8   location       57 non-null     int64  \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 4.1+ KB\n",
      "None\n",
      "  network channel station                                       data  \\\n",
      "0      ZZ     HHZ    FWU3  [ 2569  -655   825 ... -1025  -807  -208]   \n",
      "1      ZZ     HHZ    FWU3  [ 1627   296 -2155 ... -2112  2282   628]   \n",
      "2      ZZ     HHZ    FWU3        [-404 -159 -254 ... 1175 1265 1308]   \n",
      "3      ZZ     HHZ    FWU3  [-1508 -2152  -469 ...  9523 23239 28757]   \n",
      "4      ZZ     HHZ    FWU3  [ -566 -2275 -3280 ...  -338  -752  -892]   \n",
      "\n",
      "                      endtime            starttime  Unnamed: 0  sampling_rate  \\\n",
      "0  2019-12-05T23:59:59.996000  2019-12-05T00:00:00           0          250.0   \n",
      "1  2019-12-25T23:59:59.996000  2019-12-25T00:00:00           1          250.0   \n",
      "2  2019-11-30T23:59:59.996000  2019-11-30T00:00:00           2          250.0   \n",
      "3  2019-11-03T23:59:59.996000  2019-11-03T00:00:00           3          250.0   \n",
      "4  2019-12-11T23:59:59.996000  2019-12-11T00:00:00           4          250.0   \n",
      "\n",
      "   location  \n",
      "0        10  \n",
      "1        10  \n",
      "2        10  \n",
      "3        10  \n",
      "4        10  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_csv_files(file1, file2, output_path):\n",
    "    # Read the CSV files, assuming the first row is the header\n",
    "    df1 = pd.read_csv(file1, header=0)\n",
    "    df2 = pd.read_csv(file2, header=0)\n",
    "\n",
    "    # Ensure consistent column names\n",
    "    common_columns = set(df1.columns).intersection(set(df2.columns))\n",
    "    df1 = df1[list(common_columns)]\n",
    "    df2 = df2[list(common_columns)]\n",
    "\n",
    "    # Concatenate the DataFrames\n",
    "    merged_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "\n",
    "    # Save the merged DataFrame to a new CSV file\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# Usage\n",
    "file1 = '/notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data5.csv'\n",
    "file2 = '/notebooks/Mine-folder/output/FWU3/currentCSVs/merged_seismic_data6.csv'\n",
    "output_path = '/notebooks/Mine-folder/output/FWU3/currentCSVs/HHZDcsv1.csv'\n",
    "\n",
    "# Merge the CSV files\n",
    "merged_dataframe = merge_csv_files(file1, file2, output_path)\n",
    "\n",
    "print(\"\\nMerged DataFrame information:\")\n",
    "print(merged_dataframe.info())\n",
    "print(merged_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged DataFrame information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173 entries, 0 to 172\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   network        173 non-null    object \n",
      " 1   channel        173 non-null    object \n",
      " 2   station        173 non-null    object \n",
      " 3   data           173 non-null    object \n",
      " 4   endtime        173 non-null    object \n",
      " 5   starttime      173 non-null    object \n",
      " 6   Unnamed: 0     173 non-null    int64  \n",
      " 7   sampling_rate  173 non-null    float64\n",
      " 8   location       173 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 12.3+ KB\n",
      "None\n",
      "  network channel station                                             data  \\\n",
      "0      ZZ     HHE    FWU3  [ -2718   -384  -1595 ...  11287 -15821  -3071]   \n",
      "1      ZZ     HHE    FWU3        [ 1313  1352  1389 ... -1601   130  1031]   \n",
      "2      ZZ     HHE    FWU3        [-7410 -5221  3344 ... -3956  4921 11622]   \n",
      "3      ZZ     HHE    FWU3  [-11938  -1006  11098 ...   -350   -485   -682]   \n",
      "4      ZZ     HHE    FWU3        [-6507 -5165 -3379 ...  -315    59  -251]   \n",
      "\n",
      "                      endtime            starttime  Unnamed: 0  sampling_rate  \\\n",
      "0  2019-12-26T23:59:59.996000  2019-12-26T00:00:00           0          250.0   \n",
      "1  2019-11-02T23:59:59.996000  2019-11-02T00:00:00           1          250.0   \n",
      "2  2019-12-22T23:59:59.996000  2019-12-22T00:00:00           2          250.0   \n",
      "3  2019-12-15T23:59:59.996000  2019-12-15T00:00:00           3          250.0   \n",
      "4  2019-11-28T23:59:59.996000  2019-11-28T00:00:00           4          250.0   \n",
      "\n",
      "   location  \n",
      "0        10  \n",
      "1        10  \n",
      "2        10  \n",
      "3        10  \n",
      "4        10  \n",
      "    network channel station                                             data  \\\n",
      "168      ZZ     HHZ    FWU3  [  7693  -7872 -10247 ...   1832   1693   1579]   \n",
      "169      ZZ     HHZ    FWU3        [ 2307   199 -1986 ...    74   159    30]   \n",
      "170      ZZ     HHZ    FWU3        [ -184    19   157 ... -3287 -2833 -1497]   \n",
      "171      ZZ     HHZ    FWU3        [ 1768  -774 -5083 ... 14520   249 -7159]   \n",
      "172      ZZ     HHZ    FWU3              [ 165  138  149 ... -958 -908 -681]   \n",
      "\n",
      "                        endtime            starttime  Unnamed: 0  \\\n",
      "168  2019-11-05T18:49:16.284000  2019-11-05T00:00:00          24   \n",
      "169  2019-11-20T23:59:59.996000  2019-11-20T00:00:00          25   \n",
      "170  2019-11-15T23:59:59.996000  2019-11-15T00:00:00          26   \n",
      "171  2019-12-27T01:55:33.660000  2019-12-27T00:00:00          27   \n",
      "172  2019-11-29T23:59:59.996000  2019-11-29T00:00:00          28   \n",
      "\n",
      "     sampling_rate  location  \n",
      "168          250.0        10  \n",
      "169          250.0        10  \n",
      "170          250.0        10  \n",
      "171          250.0        10  \n",
      "172          250.0        10  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_csv_files(file1, file2, file3, output_path):\n",
    "    # Read the CSV files, assuming the first row is the header\n",
    "    df1 = pd.read_csv(file1, header=0)\n",
    "    df2 = pd.read_csv(file2, header=0)\n",
    "    df3 = pd.read_csv(file3, header=0)\n",
    "\n",
    "    # Ensure consistent column names\n",
    "    common_columns = set(df1.columns).intersection(set(df2.columns)).intersection(set(df3.columns))\n",
    "    df1 = df1[list(common_columns)]\n",
    "    df2 = df2[list(common_columns)]\n",
    "    df3 = df3[list(common_columns)]\n",
    "\n",
    "    # Concatenate the DataFrames\n",
    "    merged_df = pd.concat([df1, df2, df3], axis=0, ignore_index=True)\n",
    "\n",
    "    # Save the merged DataFrame to a new CSV file\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# Usage\n",
    "file1 = '/notebooks/Mine-folder/output/FWU3/currentCSVs/HHEDcsv1.csv'\n",
    "file2 = '/notebooks/Mine-folder/output/FWU3/currentCSVs/HHNDcsv1.csv'\n",
    "file3 = '/notebooks/Mine-folder/output/FWU3/currentCSVs/HHZDcsv1.csv'\n",
    "output_path = '/notebooks/Mine-folder/output/FWU3/currentCSVs/FWU3_csv.csv'\n",
    "\n",
    "# Merge the CSV files\n",
    "merged_dataframe = merge_csv_files(file1, file2, file3, output_path)\n",
    "\n",
    "print(\"\\nMerged DataFrame information:\")\n",
    "print(merged_dataframe.info())\n",
    "print(merged_dataframe.head())\n",
    "print(merged_dataframe.tail())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
